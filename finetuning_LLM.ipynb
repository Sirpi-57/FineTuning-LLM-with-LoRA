{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMLeLXUNSw1vkBhM77iz9tP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5M36O31PC44","executionInfo":{"status":"ok","timestamp":1727960762159,"user_tz":-330,"elapsed":27727,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}},"outputId":"4980121e-283b-4aba-e950-65175dd2dc66"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.6.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.1 which is incompatible.\n","cudf-cu12 24.6.1 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Collecting numpy\n","  Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.1.1\n","    Uninstalling numpy-2.1.1:\n","      Successfully uninstalled numpy-2.1.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.6.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.1 which is incompatible.\n","cudf-cu12 24.6.1 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 17.0.0 which is incompatible.\n","cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.1 which is incompatible.\n","gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.1 which is incompatible.\n","gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.1 which is incompatible.\n","pytensor 2.25.4 requires numpy<2,>=1.17.0, but you have numpy 2.1.1 which is incompatible.\n","rmm-cu12 24.6.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.1 which is incompatible.\n","tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.1 which is incompatible.\n","thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.1.1\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.1)\n","Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (2.1.1)\n"]}],"source":["!pip install -q datasets\n","!pip install -q bitsandbytes\n","!pip install -q peft\n","!pip install --upgrade -q pyarrow\n","!pip install --upgrade datasets\n","!pip install --force-reinstall numpy\n","!pip install --upgrade scipy"]},{"cell_type":"code","source":["from typing import Dict, List\n","from datasets import Dataset, load_dataset, disable_caching # this should now work with the reinstalled version\n","disable_caching()\n","from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n","from peft import PeftModel, PeftConfig\n","from transformers import BitsAndBytesConfig\n","import torch\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"KSqEdfrBPz-j","executionInfo":{"status":"error","timestamp":1727960767188,"user_tz":-330,"elapsed":573,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"668c6e2b-1170-4ba2-fb3d-43e80627da05"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-4-0b16b3cda4ee>\", line 2, in <cell line: 2>\n","    from datasets import Dataset, load_dataset, disable_caching # this should now work with the reinstalled version\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\", line 17, in <module>\n","    from .arrow_dataset import Dataset\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 60, in <module>\n","    import pyarrow as pa\n","  File \"/usr/local/lib/python3.10/dist-packages/pyarrow/__init__.py\", line 65, in <module>\n","    import pyarrow.lib as _lib\n"]},{"output_type":"error","ename":"AttributeError","evalue":"_ARRAY_API not found","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"]},{"output_type":"error","ename":"ImportError","evalue":"numpy.core.multiarray failed to import","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0b16b3cda4ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_caching\u001b[0m \u001b[0;31m# this should now work with the reinstalled version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisable_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"3.0.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murl_to_fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0m_gc_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misenabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0m_gc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_gc_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0m_gc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/lib.pyx\u001b[0m in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"source":["!pip install -q datasets\n","!pip install -q bitsandbytes\n","!pip install -q peft\n","!pip install --upgrade -q pyarrow\n","!pip install --upgrade datasets\n","!pip install --force-reinstall numpy\n","!pip install --upgrade scipy\n","\n","from typing import Dict, List # List is imported from the typing module\n","from datasets import Dataset, load_dataset, disable_caching # this should now work with the reinstalled version\n","disable_caching()\n","from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n","from peft import PeftModel, PeftConfig\n","from transformers import BitsAndBytesConfig\n","import torch\n","from torch.utils.data import Dataset, DataLoader"],"cell_type":"code","metadata":{"id":"RurKPT9OfTJK","executionInfo":{"status":"error","timestamp":1727960818190,"user_tz":-330,"elapsed":22585,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}},"outputId":"606dedc9-2679-43c6-a428-6076f3cf03b2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Collecting numpy\n","  Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.1.1\n","    Uninstalling numpy-2.1.1:\n","      Successfully uninstalled numpy-2.1.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.6.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.1 which is incompatible.\n","cudf-cu12 24.6.1 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 17.0.0 which is incompatible.\n","cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.1 which is incompatible.\n","gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.1 which is incompatible.\n","gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.1 which is incompatible.\n","pytensor 2.25.4 requires numpy<2,>=1.17.0, but you have numpy 2.1.1 which is incompatible.\n","rmm-cu12 24.6.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.1.1 which is incompatible.\n","tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.1 which is incompatible.\n","thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.1.1\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.1)\n","Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (2.1.1)\n"]},{"output_type":"stream","name":"stderr","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-5-f6818a445c41>\", line 10, in <cell line: 10>\n","    from datasets import Dataset, load_dataset, disable_caching # this should now work with the reinstalled version\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\", line 17, in <module>\n","    from .arrow_dataset import Dataset\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 60, in <module>\n","    import pyarrow as pa\n","  File \"/usr/local/lib/python3.10/dist-packages/pyarrow/__init__.py\", line 65, in <module>\n","    import pyarrow.lib as _lib\n"]},{"output_type":"error","ename":"AttributeError","evalue":"_ARRAY_API not found","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"]},{"output_type":"error","ename":"ImportError","evalue":"numpy.core.multiarray failed to import","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-f6818a445c41>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m \u001b[0;31m# List is imported from the typing module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_caching\u001b[0m \u001b[0;31m# this should now work with the reinstalled version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdisable_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"3.0.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murl_to_fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0m_gc_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misenabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0m_gc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_gc_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0m_gc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/lib.pyx\u001b[0m in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["dataset = load_dataset(\"MBZUAI/LaMini-instruction\", split = \"train\")"],"metadata":{"id":"2K8nWlnPQ0jV","executionInfo":{"status":"aborted","timestamp":1727959193941,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["small_dataset = dataset.select(i for i in range(200))\n","print(small_dataset)\n","print(small_dataset[0])"],"metadata":{"id":"X4U_RPbaSOt5","executionInfo":{"status":"aborted","timestamp":1727959193941,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_template = \"\"\" Below is an instruction that decribes a task, Write a respone that appropriately completes the request, Instruction : {instruction} \\n Response:\"\"\"\n","answer_template = \"\"\"{response}\"\"\"\n","\n","# create a function to add keys in the dictionary for prompt, answer and whole text\n","\n","def _add_text(rec):\n","  instructions = rec[\"instruction\"]\n","  response = rec[\"response\"]\n","  if not instructions or not response:\n","    raise ValueError(\"instruction and response cannot be empty\")\n","  rec[\"prompt\"] = prompt_template.format(instruction = instructions)\n","  rec[\"answer\"] = answer_template.format(response = response)\n","  rec[\"text\"] = rec[\"prompt\"] + rec[\"answer\"]\n","\n","  return rec\n","\n","small_dataset = small_dataset.map(_add_text)\n","print(small_dataset[0])\n"],"metadata":{"id":"R9lKZTTHSjG8","executionInfo":{"status":"aborted","timestamp":1727959193942,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id = \"Qwen/Qwen2.5-7B\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","model_id,\n","device_map = \"auto\",\n","torch_dtype = torch.float16,\n","load_in_8bit = True\n"," )"],"metadata":{"id":"q38cX65ATjtk","executionInfo":{"status":"aborted","timestamp":1727959193942,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from functools import partial\n","from transformers import DataCollatorForSeq2Seq\n","\n","MAX_LENGTH = 256\n","\n","# Preprocess function to tokenize the input and response\n","def _preprocess_batch(batch: Dict[str, List[str]]):\n","    # Corrected 'test_target' to 'text_target'\n","    model_input = tokenizer(batch[\"text\"], text_target=batch[\"response\"],\n","                            truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n","    model_input[\"labels\"] = model_input[\"input_ids\"]\n","    return model_input\n","\n","# Use partial to create the preprocessing function\n","_preprocessing_function = partial(_preprocess_batch)\n","\n","# Apply the preprocessing function to the dataset\n","encode_small_dataset = small_dataset.map(_preprocessing_function, batched=True, remove_columns=['instruction', 'response', 'prompt', 'answer'])\n","\n","# Filter the dataset for sequences within the max length\n","processed_dataset = encode_small_dataset.filter(lambda rec: len(rec[\"input_ids\"]) <= MAX_LENGTH)\n","\n","# Split dataset into training and test sets\n","split_dataset = processed_dataset.train_test_split(test_size=0.2, seed=42)\n","\n","# Create a data collator for sequence-to-sequence tasks\n","data_collator = DataCollatorForSeq2Seq(model=model, tokenizer=tokenizer, max_length=MAX_LENGTH, pad_to_multiple_of=8, padding=\"max_length\")\n"],"metadata":{"id":"JD5oUIabWTCQ","executionInfo":{"status":"aborted","timestamp":1727959193943,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n"],"metadata":{"id":"ooenDwZaYeVj","executionInfo":{"status":"aborted","timestamp":1727959193943,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LORA_R = 256\n","LORA_ALPHA = 512\n","LORA_DROPOUT = 0.05\n","\n","# Define LoRA config\n","\n","lora_config = LoraConfig(\n","    r=LORA_R,\n","    lora_alpha=LORA_ALPHA,\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    lora_dropout=LORA_DROPOUT,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = prepare_model_for_kbit_training(model)\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()"],"metadata":{"id":"fvr9QNIAaq5V","executionInfo":{"status":"aborted","timestamp":1727959193944,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","import bitsandbytes\n","\n","EPOCHS = 5\n","LEARNING_RATE = 2e-5\n","MODEL_SAVE_FOLDER_NAME = \"Qwen2.5-7B-lora\"\n","\n","\n","training_args = TrainingArguments(\n","    output_dir=MODEL_SAVE_FOLDER_NAME,\n","    overwrite_output_dir=True,\n","    fp16=True,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    learning_rate=LEARNING_RATE,\n","    num_train_epochs=EPOCHS,\n","    logging_strategy=\"epoch\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2\n",")\n","\n","split_dataset = processed_dataset.train_test_split(test_size=0.2, seed=42)\n","\n","print(split_dataset)\n","\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=split_dataset[\"train\"],\n","    eval_dataset=split_dataset[\"test\"]\n",")\n","\n","model.config.use_cache = False\n","\n","trainer.train()\n"],"metadata":{"id":"sU28DqgAbRy_","executionInfo":{"status":"aborted","timestamp":1727959193945,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","def postprocess(response):\n","    message = response.split(\"Response:\")\n","    if len(message) < 2:\n","        raise ValueError(\"Invalid Template for Prompt: The Template should include the term 'Response:'\")\n","    return \"\".join(message[1:])\n","\n","inf_pipeline = pipeline(\n","    task=\"text-generation\",\n","    model=trainer.model,\n","    tokenizer=tokenizer,\n","    max_length=256,\n","    temperature=0.0,\n","    trust_remote_code=True,\n","    device_map=\"auto\"\n",")\n","\n","\n","inference_prompt = \"Write me a recipe for Dosa\"\n","response = inf_pipeline(prompt_template.format(instruction=inference_prompt))[0][\"generated_text\"]\n","formatted_response = postprocess(response)\n","\n","\n","print(formatted_response)\n"],"metadata":{"id":"puXsCxrLmNDR","executionInfo":{"status":"aborted","timestamp":1727959193945,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inference_prompt = \"Write me a recipe for Pizza\"\n","response = inf_pipeline(prompt_template.format(instruction=inference_prompt))[0][\"generated_text\"]\n","formatted_response = postprocess(response)\n","\n","\n","print(formatted_response)"],"metadata":{"id":"y-15yF7Omsn3","executionInfo":{"status":"aborted","timestamp":1727959193945,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inference_prompt = \"Write me the process to get Schengen visa\"\n","response = inf_pipeline(prompt_template.format(instruction=inference_prompt))[0][\"generated_text\"]\n","formatted_response = postprocess(response)\n","\n","\n","print(formatted_response)"],"metadata":{"id":"Wulzq0MRnQXY","executionInfo":{"status":"aborted","timestamp":1727959193946,"user_tz":-330,"elapsed":18,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QwoDoQPBo3pj","executionInfo":{"status":"aborted","timestamp":1727959193946,"user_tz":-330,"elapsed":18,"user":{"displayName":"Sirpi","userId":"05374407644019621820"}}},"execution_count":null,"outputs":[]}]}